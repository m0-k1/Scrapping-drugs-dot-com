{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rRqUV9tv5Zf-"
   },
   "source": [
    "## Extracting \"Uses\" section of the various medicines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "auVsVI-h5ZgB"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import these two modules bs4 for selecting HTML tags easily\n",
    "from bs4 import BeautifulSoup\n",
    "# requests module is easy to operate some people use urllib but I prefer this one because it is easy to use.\n",
    "import requests\n",
    "\n",
    "import pathlib\n",
    "from pandas import DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DdTlea6M5ZgI"
   },
   "outputs": [],
   "source": [
    "url = 'https://www.drugs.com/npc/' \n",
    "url2 = 'https://www.drugs.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_SdgPD0o5ZgO"
   },
   "outputs": [],
   "source": [
    "#Requests module use to data from given url\n",
    "source=requests.get(url)\n",
    "\n",
    "# BeautifulSoup is used for getting HTML structure from requests response.\n",
    "soup=BeautifulSoup(source.text,'html')\n",
    "body = soup.body.findAll ('div',{'id': 'a2z'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZL-ko3S25ZgT"
   },
   "outputs": [],
   "source": [
    "#Extracting the links present on the web page for further exploration\n",
    "medicines = {}\n",
    "links = []\n",
    "a = 0\n",
    "for tags in body:\n",
    "    for t in tags.find_all('a', href=True):\n",
    "        links.append(t.get('href'))\n",
    "        medicines[a] = t.get_text('href')\n",
    "        a += 1\n",
    "#print(medicines)\n",
    "#print(links) \n",
    "keys = list(medicines.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WFSNvvr35ZgX"
   },
   "outputs": [],
   "source": [
    "# function for extraction of required data using HTML tags\n",
    "def item_uses(soups_,item):\n",
    "    common_names = ''\n",
    "    for tags in soups_.find_all(\"div\",{\"class\": \"block yya\"}) :\n",
    "        for t in tags.find_all(\"p\"):\n",
    "            common_names  = common_names + '\\n' + t.get_text()\n",
    "            \n",
    "    if len(common_names) != 0 :\n",
    "        return(common_names)\n",
    "    else :\n",
    "        return((item_uses2(soups_,item)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i2Si4Ce65Zgb"
   },
   "outputs": [],
   "source": [
    "# function for extraction of required data by converting the contents as text and searching the required section\n",
    "def item_uses2 (soups_,item2):\n",
    "    \n",
    "    text = \"What is it used for?\"\n",
    "    \n",
    "    #Extracting the text present in class = \"contentBox\"\n",
    "    for tags in soups_.find_all(\"div\",{\"class\": \"contentBox\"}):\n",
    "        string = (tags.get_text())\n",
    "        \n",
    "    pos = string.find(text)\n",
    "    \n",
    "    if pos == -1:\n",
    "        return(item_uses3(soups_, item2))\n",
    "    else:\n",
    "        new_string = string[pos+len(text)+1:]\n",
    "\n",
    "        end = new_string.find(\"What\")\n",
    "\n",
    "        desired_output =  (new_string[:end]).rstrip()\n",
    "        return(desired_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for extraction of required data by converting the contents as text and searching the required section\n",
    "def item_uses3 (soups_,item3):\n",
    "    \n",
    "    text = \"What is \" + item3 + \" used for?\"\n",
    "    \n",
    "    #Extracting the text present in class = \"contentBox\"\n",
    "    for tags in soups_.find_all(\"div\",{\"class\": \"contentBox\"}):\n",
    "        string = (tags.get_text())\n",
    "        \n",
    "    pos = string.find(text)\n",
    "    \n",
    "    if pos == -1:\n",
    "        return(None)\n",
    "    else:\n",
    "        new_string = string[pos+len(text)+1:]\n",
    "\n",
    "        end = new_string.find(\"What\")\n",
    "\n",
    "        desired_output =  (new_string[:end]).rstrip()\n",
    "        return(desired_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GxUB3xoY5Zgt",
    "outputId": "152ea4e7-a70f-4a46-d905-b68040797d67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File does not exist\n",
      " Creating the file\n",
      "File created successfully with filename -  Uses.csv\n",
      "No.of links are -  259\n"
     ]
    }
   ],
   "source": [
    "# Main function \n",
    "start = 0\n",
    "names = {}\n",
    "# First checking the file exist or not. If it exists, checking whether it is empty or not\n",
    "name = 'Uses.csv'\n",
    "file_name = pathlib.Path(name)\n",
    "if file_name.exists ():\n",
    "    print (\"File exist.\")\n",
    "    try :\n",
    "        print(\"Reading the file now\")\n",
    "        df = pd.read_csv(name, index_col = 0)\n",
    "        print(len(df))\n",
    "\n",
    "        start = (len(df) - 1)\n",
    "    except:\n",
    "        print(\"File is empty\")\n",
    "        \n",
    "    \n",
    "else:\n",
    "    print (\"File does not exist\\n\", \"Creating the file\")\n",
    "    file = open(name,\"w+\")\n",
    "    print(\"File created successfully with filename - \",name)\n",
    "print(\"No.of links are - \", len(links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8YTVmQEx5Zgy",
    "outputId": "c58f2adc-5bc2-4419-df02-b28108acb449"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Extracting data for - 5-Hydroxytryptophan\n",
      "Success in extracting data for -  5-Hydroxytryptophan\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Acai\n",
      "Success in extracting data for -  Acai\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Acerola\n",
      "Success in extracting data for -  Acerola\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Acetyl-L-Carnitine\n",
      "Success in extracting data for -  Acetyl-L-Carnitine\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Acidophilus\n",
      "Success in extracting data for -  Acidophilus\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Aconite\n",
      "Success in extracting data for -  Aconite\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Adrenal Extract\n",
      "Success in extracting data for -  Adrenal Extract\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - African Mango\n",
      "Success in extracting data for -  African Mango\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Alfalfa\n",
      "Success in extracting data for -  Alfalfa\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Aloe\n",
      "Success in extracting data for -  Aloe\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Alpha-Lipoic Acid\n",
      "Success in extracting data for -  Alpha-Lipoic Acid\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Angelica\n",
      "Success in extracting data for -  Angelica\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Anise\n",
      "Success in extracting data for -  Anise\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Aortic Extract\n",
      "Success in extracting data for -  Aortic Extract\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Arabinoxylane\n",
      "Success in extracting data for -  Arabinoxylane\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Arginine\n",
      "Success in extracting data for -  Arginine\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Arnica\n",
      "Success in extracting data for -  Arnica\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Artichoke\n",
      "Success in extracting data for -  Artichoke\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Ashwagandha\n",
      "Success in extracting data for -  Ashwagandha\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Astragalus\n",
      "Success in extracting data for -  Astragalus\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Barberry\n",
      "Success in extracting data for -  Barberry\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Barley Grass\n",
      "Success in extracting data for -  Barley Grass\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Bayberry\n",
      "Success in extracting data for -  Bayberry\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Bee Pollen\n",
      "Success in extracting data for -  Bee Pollen\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Beta Glucans\n",
      "Success in extracting data for -  Beta Glucans\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Beta-Carotene\n",
      "Success in extracting data for -  Beta-Carotene\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Beta-Sitosterol\n",
      "Success in extracting data for -  Beta-Sitosterol\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Betaine Hydrochloride\n",
      "Success in extracting data for -  Betaine Hydrochloride\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Betel Nut\n",
      "Success in extracting data for -  Betel Nut\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Betony\n",
      "Success in extracting data for -  Betony\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Bilberry\n",
      "Success in extracting data for -  Bilberry\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Biotin\n",
      "Success in extracting data for -  Biotin\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Bitter Melon\n",
      "Success in extracting data for -  Bitter Melon\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Bitter Orange\n",
      "Success in extracting data for -  Bitter Orange\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Black Cohosh\n",
      "Success in extracting data for -  Black Cohosh\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Bladderwrack\n",
      "Success in extracting data for -  Bladderwrack\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Bloodroot\n",
      "Success in extracting data for -  Bloodroot\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Boldo\n",
      "Success in extracting data for -  Boldo\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Boneset\n",
      "Success in extracting data for -  Boneset\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Borage\n",
      "Success in extracting data for -  Borage\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Boron\n",
      "Success in extracting data for -  Boron\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Bovine Colostrum\n",
      "Success in extracting data for -  Bovine Colostrum\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Brahmi\n",
      "Success in extracting data for -  Brahmi\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Branched-Chain Amino Acids\n",
      "Success in extracting data for -  Branched-Chain Amino Acids\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Brewer's Yeast\n",
      "Success in extracting data for -  Brewer's Yeast\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Bromelain\n",
      "Success in extracting data for -  Bromelain\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Buchu\n",
      "Success in extracting data for -  Buchu\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Bugleweed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in extracting data for -  Bugleweed\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Bupleurum\n",
      "Success in extracting data for -  Bupleurum\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Burdock\n",
      "Success in extracting data for -  Burdock\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Butcher's Broom\n",
      "Success in extracting data for -  Butcher's Broom\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Butterbur\n",
      "Success in extracting data for -  Butterbur\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Calanolide A\n",
      "Success in extracting data for -  Calanolide A\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Calendula\n",
      "Success in extracting data for -  Calendula\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Caprylic Acid\n",
      "Success in extracting data for -  Caprylic Acid\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Caprylidene\n",
      "Success in extracting data for -  Caprylidene\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Capsicum Peppers\n",
      "Success in extracting data for -  Capsicum Peppers\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Carnitine\n",
      "Success in extracting data for -  Carnitine\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Cascara\n",
      "Success in extracting data for -  Cascara\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Cat's Claw\n",
      "Success in extracting data for -  Cat's Claw\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Catnip\n",
      "Success in extracting data for -  Catnip\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Centaury\n",
      "Success in extracting data for -  Centaury\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Chamomile\n",
      "Success in extracting data for -  Chamomile\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Chaparral\n",
      "Success in extracting data for -  Chaparral\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Chaste Tree\n",
      "Success in extracting data for -  Chaste Tree\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Chickweed\n",
      "Success in extracting data for -  Chickweed\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Chicory\n",
      "Success in extracting data for -  Chicory\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Chinese Cucumber\n",
      "Success in extracting data for -  Chinese Cucumber\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Chitosan\n",
      "Success in extracting data for -  Chitosan\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Chlorophyll\n",
      "Success in extracting data for -  Chlorophyll\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Chondroitin\n",
      "Success in extracting data for -  Chondroitin\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Chromium\n",
      "Success in extracting data for -  Chromium\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Cinnamon\n",
      "Success in extracting data for -  Cinnamon\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Clove\n",
      "Success in extracting data for -  Clove\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Coleus\n",
      "Success in extracting data for -  Coleus\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Coltsfoot\n",
      "Success in extracting data for -  Coltsfoot\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Comfrey\n",
      "Success in extracting data for -  Comfrey\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Cordyceps\n",
      "Success in extracting data for -  Cordyceps\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Crampbark\n",
      "Success in extracting data for -  Crampbark\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Cranberry\n",
      "Success in extracting data for -  Cranberry\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Creatine\n",
      "Success in extracting data for -  Creatine\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Cumin\n",
      "Success in extracting data for -  Cumin\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Damiana\n",
      "Success in extracting data for -  Damiana\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Dandelion\n",
      "Success in extracting data for -  Dandelion\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Danshen\n",
      "Success in extracting data for -  Danshen\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Deer Velvet\n",
      "Success in extracting data for -  Deer Velvet\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Dehydroepiandrosterone\n",
      "Success in extracting data for -  Dehydroepiandrosterone\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Devil's Claw\n",
      "Success in extracting data for -  Devil's Claw\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Dolomite\n",
      "Success in extracting data for -  Dolomite\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Dong Quai\n",
      "Success in extracting data for -  Dong Quai\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Dragon's Blood\n",
      "Success in extracting data for -  Dragon's Blood\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Echinacea\n",
      "Success in extracting data for -  Echinacea\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Elderberry\n",
      "Success in extracting data for -  Elderberry\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Eleutherococcus\n",
      "Success in extracting data for -  Eleutherococcus\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Emu Oil\n",
      "Success in extracting data for -  Emu Oil\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Ephedra\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in extracting data for -  Ephedra\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Evening Primrose Oil\n",
      "Success in extracting data for -  Evening Primrose Oil\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Eyebright\n",
      "Success in extracting data for -  Eyebright\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - False Unicorn\n",
      "Success in extracting data for -  False Unicorn\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Fennel\n",
      "Success in extracting data for -  Fennel\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Fenugreek\n",
      "Success in extracting data for -  Fenugreek\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Feverfew\n",
      "Success in extracting data for -  Feverfew\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Fish Oil\n",
      "Success in extracting data for -  Fish Oil\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Flax\n",
      "Success in extracting data for -  Flax\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Fo Ti\n",
      "Success in extracting data for -  Fo Ti\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Forskolin\n",
      "Success in extracting data for -  Forskolin\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Frankincense, Indian\n",
      "Success in extracting data for -  Frankincense, Indian\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Fruit Acids\n",
      "Success in extracting data for -  Fruit Acids\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Fumitory\n",
      "Success in extracting data for -  Fumitory\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Gamma Linolenic Acid (GLA)\n",
      "Success in extracting data for -  Gamma Linolenic Acid (GLA)\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Gamma Oryzanol\n",
      "Success in extracting data for -  Gamma Oryzanol\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Garcinia (Hydroxycitric Acid)\n",
      "Success in extracting data for -  Garcinia (Hydroxycitric Acid)\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Garlic\n",
      "Success in extracting data for -  Garlic\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Gelsemium\n",
      "Success in extracting data for -  Gelsemium\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Gentian\n",
      "Success in extracting data for -  Gentian\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Ginger\n",
      "Success in extracting data for -  Ginger\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Ginkgo\n",
      "Success in extracting data for -  Ginkgo\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Ginseng\n",
      "Success in extracting data for -  Ginseng\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Glucomannan\n",
      "Success in extracting data for -  Glucomannan\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Glucosamine\n",
      "Success in extracting data for -  Glucosamine\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Glutamine\n",
      "Success in extracting data for -  Glutamine\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Glutathione\n",
      "Success in extracting data for -  Glutathione\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Golden Seal\n",
      "Success in extracting data for -  Golden Seal\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Gotu Kola\n",
      "Success in extracting data for -  Gotu Kola\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Grape Seed\n",
      "Success in extracting data for -  Grape Seed\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Grapefruit\n",
      "Success in extracting data for -  Grapefruit\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Green Tea\n",
      "Success in extracting data for -  Green Tea\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Guarana\n",
      "Success in extracting data for -  Guarana\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Guggul\n",
      "Success in extracting data for -  Guggul\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Gymnema\n",
      "Success in extracting data for -  Gymnema\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Hawthorn\n",
      "Success in extracting data for -  Hawthorn\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Hibiscus\n",
      "Success in extracting data for -  Hibiscus\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Holly\n",
      "Success in extracting data for -  Holly\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Hops\n",
      "Success in extracting data for -  Hops\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Horehound\n",
      "Success in extracting data for -  Horehound\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Horny Goat Weed\n",
      "Success in extracting data for -  Horny Goat Weed\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Horse Chestnut\n",
      "Success in extracting data for -  Horse Chestnut\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Horseradish\n",
      "Success in extracting data for -  Horseradish\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Horsetail\n",
      "Success in extracting data for -  Horsetail\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Huperzine A\n",
      "Success in extracting data for -  Huperzine A\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Hyaluronic Acid\n",
      "Success in extracting data for -  Hyaluronic Acid\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Hyssop\n",
      "Success in extracting data for -  Hyssop\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Inositol Hexaphosphate\n",
      "Success in extracting data for -  Inositol Hexaphosphate\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Ipecac\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in extracting data for -  Ipecac\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Jojoba\n",
      "Success in extracting data for -  Jojoba\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Juniper\n",
      "Success in extracting data for -  Juniper\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Kalonji\n",
      "Success in extracting data for -  Kalonji\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Kaolin Hydrated Aluminum Silicate\n",
      "Success in extracting data for -  Kaolin Hydrated Aluminum Silicate\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Kava\n",
      "Success in extracting data for -  Kava\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Kombucha\n",
      "Success in extracting data for -  Kombucha\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Kudzu\n",
      "Success in extracting data for -  Kudzu\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - L-arginine\n",
      "Success in extracting data for -  L-arginine\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - L-Theanine\n",
      "Success in extracting data for -  L-Theanine\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - L-Tryptophan\n",
      "Success in extracting data for -  L-Tryptophan\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Lavender\n",
      "Success in extracting data for -  Lavender\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Lecithin\n",
      "Success in extracting data for -  Lecithin\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Lemon Balm\n",
      "Success in extracting data for -  Lemon Balm\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Lemon Verbena\n",
      "Success in extracting data for -  Lemon Verbena\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Licorice\n",
      "Success in extracting data for -  Licorice\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Linden\n",
      "Success in extracting data for -  Linden\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Lobelia\n",
      "Success in extracting data for -  Lobelia\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Lutein\n",
      "Success in extracting data for -  Lutein\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Lycopene\n",
      "Success in extracting data for -  Lycopene\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Lysine\n",
      "Success in extracting data for -  Lysine\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Ma Huang\n",
      "Success in extracting data for -  Ma Huang\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Maca\n",
      "Success in extracting data for -  Maca\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Maitake\n",
      "Success in extracting data for -  Maitake\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Marijuana\n",
      "Success in extracting data for -  Marijuana\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Maritime Pine\n",
      "Success in extracting data for -  Maritime Pine\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Maté\n",
      "Success in extracting data for -  Maté\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Meadowsweet\n",
      "Success in extracting data for -  Meadowsweet\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Melatonin\n",
      "Success in extracting data for -  Melatonin\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Methylsulfonylmethane (MSM)\n",
      "Success in extracting data for -  Methylsulfonylmethane (MSM)\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Milk Thistle\n",
      "Success in extracting data for -  Milk Thistle\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Mistletoe\n",
      "Success in extracting data for -  Mistletoe\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Muira Puama\n",
      "Success in extracting data for -  Muira Puama\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Mullein\n",
      "Success in extracting data for -  Mullein\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Myrrh\n",
      "Success in extracting data for -  Myrrh\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Neem\n",
      "Success in extracting data for -  Neem\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Nettles\n",
      "Success in extracting data for -  Nettles\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Noni\n",
      "Success in extracting data for -  Noni\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Oats\n",
      "Success in extracting data for -  Oats\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Olive Leaf\n",
      "Success in extracting data for -  Olive Leaf\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Olive Oil\n",
      "Success in extracting data for -  Olive Oil\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Onion\n",
      "Success in extracting data for -  Onion\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Oregano\n",
      "Success in extracting data for -  Oregano\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Pantothenic Acid\n",
      "Success in extracting data for -  Pantothenic Acid\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Papaya\n",
      "Success in extracting data for -  Papaya\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Parsley\n",
      "Success in extracting data for -  Parsley\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Passion Flower\n",
      "Success in extracting data for -  Passion Flower\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Pectin\n",
      "Success in extracting data for -  Pectin\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Pennyroyal\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in extracting data for -  Pennyroyal\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Peppermint\n",
      "Success in extracting data for -  Peppermint\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Periwinkle\n",
      "Success in extracting data for -  Periwinkle\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Peru Balsam\n",
      "Success in extracting data for -  Peru Balsam\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Pineapple\n",
      "Success in extracting data for -  Pineapple\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Plantain\n",
      "Success in extracting data for -  Plantain\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Poison Ivy\n",
      "Success in extracting data for -  Poison Ivy\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Policosanol\n",
      "Success in extracting data for -  Policosanol\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Probiotics\n",
      "Success in extracting data for -  Probiotics\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Propolis\n",
      "Success in extracting data for -  Propolis\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Pygeum\n",
      "Success in extracting data for -  Pygeum\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Quercetin\n",
      "Success in extracting data for -  Quercetin\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Raspberry\n",
      "Success in extracting data for -  Raspberry\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Red Clover\n",
      "Success in extracting data for -  Red Clover\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Red Yeast Rice\n",
      "Success in extracting data for -  Red Yeast Rice\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Reishi Mushroom\n",
      "Success in extracting data for -  Reishi Mushroom\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Resveratrol\n",
      "Success in extracting data for -  Resveratrol\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Rhodiola Rosea\n",
      "Success in extracting data for -  Rhodiola Rosea\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Rose Hip\n",
      "Success in extracting data for -  Rose Hip\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Rosemary\n",
      "Success in extracting data for -  Rosemary\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Royal Jelly\n",
      "Success in extracting data for -  Royal Jelly\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Safflower\n",
      "Success in extracting data for -  Safflower\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Saffron\n",
      "Success in extracting data for -  Saffron\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - SAMe\n",
      "Success in extracting data for -  SAMe\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Sandalwood\n",
      "Success in extracting data for -  Sandalwood\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Sarsaparilla\n",
      "Success in extracting data for -  Sarsaparilla\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Sarsparilla\n",
      "Success in extracting data for -  Sarsparilla\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Sassafras\n",
      "Success in extracting data for -  Sassafras\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Saw Palmetto\n",
      "Success in extracting data for -  Saw Palmetto\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Schisandra\n",
      "Success in extracting data for -  Schisandra\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Scullcap\n",
      "Success in extracting data for -  Scullcap\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Seaweed\n",
      "Success in extracting data for -  Seaweed\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Senna\n",
      "Success in extracting data for -  Senna\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Serrapeptase\n",
      "Success in extracting data for -  Serrapeptase\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Shark Derivatives\n",
      "Success in extracting data for -  Shark Derivatives\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Shark Liver Oil\n",
      "Success in extracting data for -  Shark Liver Oil\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Slippery Elm\n",
      "Success in extracting data for -  Slippery Elm\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - SOD\n",
      "Success in extracting data for -  SOD\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Soy\n",
      "Success in extracting data for -  Soy\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Spirulina\n",
      "Success in extracting data for -  Spirulina\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - St. John's Wort\n",
      "Success in extracting data for -  St. John's Wort\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Stevia\n",
      "Success in extracting data for -  Stevia\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Sweet Wormwood\n",
      "Success in extracting data for -  Sweet Wormwood\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Taheebo\n",
      "Success in extracting data for -  Taheebo\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Taurine\n",
      "Success in extracting data for -  Taurine\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Tea Tree Oil\n",
      "Success in extracting data for -  Tea Tree Oil\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Turmeric\n",
      "Success in extracting data for -  Turmeric\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Tylophora\n",
      "Success in extracting data for -  Tylophora\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Tyrosine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in extracting data for -  Tyrosine\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Ubiquinone\n",
      "Success in extracting data for -  Ubiquinone\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Uva Ursi\n",
      "Success in extracting data for -  Uva Ursi\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Valerian\n",
      "Success in extracting data for -  Valerian\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Vanadium\n",
      "Success in extracting data for -  Vanadium\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Vervain\n",
      "Success in extracting data for -  Vervain\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Vinpocetine\n",
      "Success in extracting data for -  Vinpocetine\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Vitamin E\n",
      "Success in extracting data for -  Vitamin E\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Walnut\n",
      "Success in extracting data for -  Walnut\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Wild Yam\n",
      "Success in extracting data for -  Wild Yam\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Willow Bark\n",
      "Success in extracting data for -  Willow Bark\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Wintergreen\n",
      "Success in extracting data for -  Wintergreen\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Witch Hazel\n",
      "Success in extracting data for -  Witch Hazel\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Yarrow\n",
      "Success in extracting data for -  Yarrow\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Yellow Dock\n",
      "Success in extracting data for -  Yellow Dock\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Yerba Santa\n",
      "Success in extracting data for -  Yerba Santa\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Yogurt\n",
      "Success in extracting data for -  Yogurt\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Yohimbe\n",
      "Success in extracting data for -  Yohimbe\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Yucca\n",
      "Success in extracting data for -  Yucca\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      " Extracting data for - Zinc\n",
      "Success in extracting data for -  Zinc\n",
      "Copying the data from the web........\n",
      "DONE\n",
      "**************************************************\n",
      "No.of links from which data was extracted succesfully- 259\n",
      "No.of links from which data extraction was unsuccesfull- 0\n",
      "******************** PROCESS COMPLETED ********************\n"
     ]
    }
   ],
   "source": [
    "# Iterating through the links and extracting data\n",
    "suc = 0\n",
    "fail = 0\n",
    "failed_links = []\n",
    "for i in range(start,len(links)) :\n",
    "    print (\" Extracting data for -\", keys[i])    \n",
    "    link_url = url2 + links[i]    \n",
    "    source=requests.get(link_url)\n",
    "\n",
    "    # BeautifulSoup is used for getting HTML structure from requests response.\n",
    "    soups=BeautifulSoup(source.text,'html')\n",
    "    uses = item_uses (soups, keys[i])\n",
    "    # Avoiding errors\n",
    "    try :\n",
    "        if len(uses) != 0 :\n",
    "            print(\"Success in extracting data for - \",keys[i])\n",
    "            print(\"Copying the data from the web........\")\n",
    "            names[keys[i]] = uses\n",
    "            print(\"DONE\")\n",
    "            print(\"*\"*50)\n",
    "            suc += 1\n",
    "\n",
    "\n",
    "        else :\n",
    "            print(\"No data was extracted for - \", keys[i])\n",
    "            names[keys[i]] = None\n",
    "            print(\"*\"*50)\n",
    "            fail += 1\n",
    "            failed_links.append(link_url)\n",
    "    except :\n",
    "        \n",
    "        print(\"No data was extracted for - \", keys[i])\n",
    "        names[keys[i]] = None\n",
    "        print(\"*\"*50)\n",
    "        fail += 1\n",
    "        failed_links.append(link_url)\n",
    "        \n",
    "# Let's see the links from which the data extraction was a success/unsuccess\n",
    "print(\"No.of links from which data was extracted succesfully-\", suc)\n",
    "print(\"No.of links from which data extraction was unsuccesfull-\", fail)\n",
    "print(\"*\"*20,'PROCESS COMPLETED',\"*\"*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "failed_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D6kKxMiB5Zg2",
    "outputId": "6628e992-a20b-4529-975f-a4eed97e2ae4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Medicines</th>\n",
       "      <th>Uses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5-Hydroxytryptophan</td>\n",
       "      <td>\\n5-Hydroxytryptophan is also known as 5-HTP. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Acai</td>\n",
       "      <td>\\nAcai has been used by some people to help st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Acerola</td>\n",
       "      <td>Traditional/Ethnobotanical usesAcerola is beli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Acetyl-L-Carnitine</td>\n",
       "      <td>\\nAcetyl-L-carnitine is also known as ALC. It ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Acidophilus</td>\n",
       "      <td>\\n\\n\\nTraditional/Ethnobotanical uses\\nFor sev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>Yerba Santa</td>\n",
       "      <td>Traditional/Ethnobotanical usesThe name yerba ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>Yogurt</td>\n",
       "      <td>ProbioticYogurt has been promoted to restore t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>Yohimbe</td>\n",
       "      <td>\\nYohimbe is used by some people to lose weigh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>Yucca</td>\n",
       "      <td>Traditional/Ethnobotanical usesFor centuries, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>Zinc</td>\n",
       "      <td>\\nZinc is used by some people to help with the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>259 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Medicines                                               Uses\n",
       "0    5-Hydroxytryptophan  \\n5-Hydroxytryptophan is also known as 5-HTP. ...\n",
       "1                   Acai  \\nAcai has been used by some people to help st...\n",
       "2                Acerola  Traditional/Ethnobotanical usesAcerola is beli...\n",
       "3     Acetyl-L-Carnitine  \\nAcetyl-L-carnitine is also known as ALC. It ...\n",
       "4            Acidophilus  \\n\\n\\nTraditional/Ethnobotanical uses\\nFor sev...\n",
       "..                   ...                                                ...\n",
       "254          Yerba Santa  Traditional/Ethnobotanical usesThe name yerba ...\n",
       "255               Yogurt  ProbioticYogurt has been promoted to restore t...\n",
       "256              Yohimbe  \\nYohimbe is used by some people to lose weigh...\n",
       "257                Yucca  Traditional/Ethnobotanical usesFor centuries, ...\n",
       "258                 Zinc  \\nZinc is used by some people to help with the...\n",
       "\n",
       "[259 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Appending the new values\n",
    "df_temp = DataFrame(list(names.items()),columns = ['Medicines','Uses']) \n",
    "try:\n",
    "    result = pd.concat([df,df_temp], ignore_index = True)\n",
    "    result\n",
    "except :\n",
    "    result = df_temp\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E5X2ylA55Zg5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Medicines</th>\n",
       "      <th>Uses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5-Hydroxytryptophan</td>\n",
       "      <td>\\n5-Hydroxytryptophan is also known as 5-HTP. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Acai</td>\n",
       "      <td>\\nAcai has been used by some people to help st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Acerola</td>\n",
       "      <td>Traditional/Ethnobotanical usesAcerola is beli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Acetyl-L-Carnitine</td>\n",
       "      <td>\\nAcetyl-L-carnitine is also known as ALC. It ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Acidophilus</td>\n",
       "      <td>\\n\\n\\nTraditional/Ethnobotanical uses\\nFor sev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>Yerba Santa</td>\n",
       "      <td>Traditional/Ethnobotanical usesThe name yerba ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>Yogurt</td>\n",
       "      <td>ProbioticYogurt has been promoted to restore t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>Yohimbe</td>\n",
       "      <td>\\nYohimbe is used by some people to lose weigh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>Yucca</td>\n",
       "      <td>Traditional/Ethnobotanical usesFor centuries, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>Zinc</td>\n",
       "      <td>\\nZinc is used by some people to help with the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>259 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Medicines                                               Uses\n",
       "0    5-Hydroxytryptophan  \\n5-Hydroxytryptophan is also known as 5-HTP. ...\n",
       "1                   Acai  \\nAcai has been used by some people to help st...\n",
       "2                Acerola  Traditional/Ethnobotanical usesAcerola is beli...\n",
       "3     Acetyl-L-Carnitine  \\nAcetyl-L-carnitine is also known as ALC. It ...\n",
       "4            Acidophilus  \\n\\n\\nTraditional/Ethnobotanical uses\\nFor sev...\n",
       "..                   ...                                                ...\n",
       "254          Yerba Santa  Traditional/Ethnobotanical usesThe name yerba ...\n",
       "255               Yogurt  ProbioticYogurt has been promoted to restore t...\n",
       "256              Yohimbe  \\nYohimbe is used by some people to lose weigh...\n",
       "257                Yucca  Traditional/Ethnobotanical usesFor centuries, ...\n",
       "258                 Zinc  \\nZinc is used by some people to help with the...\n",
       "\n",
       "[259 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = result.drop_duplicates()\n",
    "# writing to the file (remove \"#\" to write to the file)\n",
    "#result.to_csv(name)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Scrapping_Common_names.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
